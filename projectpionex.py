# -*- coding: utf-8 -*-
"""ProjectPionex

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gG1MQvtgeYAlO1zRURrIsxxkGeMeKIim
"""

# prompt: load data 241k-Singapore-pionex.com-Crypto-Trading-Bots-UsersDB-csv-2023 print missing fields

import pandas as pd

# Assuming the file is in your current working directory or provide the full path
file_path = '241k-Singapore-pionex.com-Crypto-Trading-Bots-UsersDB-csv-2023.csv'

try:
    df = pd.read_csv(file_path)
    missing_values = df.isnull().sum()
    print("Missing values per column:")
    print(missing_values)

except FileNotFoundError:
    print(f"Error: File not found at '{file_path}'. Please check the file path.")
except pd.errors.ParserError:
    print(f"Error: Could not parse the CSV file. Please check the file format.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

import pandas as pd

# Assuming the file is in your current working directory or provide the full path
file_path = '241k-Singapore-pionex.com-Crypto-Trading-Bots-UsersDB-csv-2023.csv'
output_file = 'garbage.csv'  # Corrected file name

try:
    df = pd.read_csv(file_path)

    # Save the DataFrame to a new CSV file
    df.to_csv(output_file, index=False)
    print(f"Data copied to '{output_file}'")

    # Print the first 5 rows
    print(df.head())

except FileNotFoundError:
    print(f"Error: File not found at '{file_path}'. Please check the file path.")
except pd.errors.ParserError:
    print(f"Error: Could not parse the CSV file. Please check the file format.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

# prompt: using the file garbage.csv "  apply the code columns_to_drop
# Lang,
# BrandCode
# create a garbage1.csv with update
# print 5 rows from garbage1.csv

import pandas as pd

# Load the dataframe.
df = pd.read_csv('garbage.csv')

# Columns to drop.
columns_to_drop = ['Lang', 'BrandCode']

# Drop the columns.
df = df.drop(columns=columns_to_drop, errors='ignore')

# Save to garbage1.csv
df.to_csv('garbage1.csv', index=False)

# Print 5 rows
print(df.head())

import pandas as pd

# File paths
file_path = 'garbage1.csv'  # Input file
output_file = 'garbage2.csv'  # Output file with formatted data

try:
    # Read the CSV file into a DataFrame
    df = pd.read_csv(file_path)

    # Format 'RegistrationDate' column if it exists
    if 'RegistrationDate' in df.columns:
        df['RegistrationDate'] = pd.to_datetime(df['RegistrationDate'], format='%d.%m.%Y %H:%M',
                                                dayfirst=True, errors='coerce')
        df['RegistrationDate'] = df['RegistrationDate'].dt.strftime('%d.%m.%y')
    else:
        print("Warning: 'RegistrationDate' column not found in the CSV file.")

    # Format 'First Name' column if it exists
    if 'First Name' in df.columns:
        df['First Name'] = df['First Name'].astype(str).str.capitalize()
    else:
        print("Warning: 'First Name' column not found in the CSV file.")

    # Format 'Last Name' column if it exists
    if 'Last Name' in df.columns:
        df['Last Name'] = df['Last Name'].astype(str).str.capitalize()
    else:
        print("Warning: 'Last Name' column not found in the CSV file.")

    # Format 'Phone' column if it exists
    if 'Phone' in df.columns:
        df['Phone'] = df['Phone'].astype(str)
    else:
        print("Warning: 'Phone' column not found in the CSV file.")

    # Save the modified DataFrame to a new CSV file
    df.to_csv(output_file, index=False)
    print(f"Data copied to '{output_file}'")

    # Display the first 5 rows of the updated DataFrame
    print(df.head())

except FileNotFoundError:
    print(f"Error: File not found at '{file_path}'. Please check the file path.")
except pd.errors.ParserError:
    print(f"Error: Could not parse the CSV file. Please check the file format.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

# prompt: # prompt: using the file garbage2.csv replace empty fields with word 'Nan' output new data to garbage3.csv

import pandas as pd

# Load the dataframe.
df = pd.read_csv('garbage2.csv')

# Replace empty fields with 'Nan'
df.fillna('Nan', inplace=True)

# Save to garbage3.csv
df.to_csv('garbage3.csv', index=False)

# Print 5 rows to verify
print(df.head())

import pandas as pd

# Load the dataframe.
df = pd.read_csv('garbage2.csv')

# Replace empty fields with 'Void'
df.fillna('Void', inplace=True)

# Save to garbage3.csv
df.to_csv('garbage3.csv', index=False)

# Print 5 rows to verify
print(df.head())

# prompt: using the file garbage3.csv rename headers as follow
# First Name = first_name
# Last Name = last_name
# RegistrationDate = reg_date
# output new data to garbage4.csv

import pandas as pd

# Load the dataframe.
df = pd.read_csv('garbage3.csv')

# Rename columns
df = df.rename(columns={
    'First Name': 'first_name',
    'Last Name': 'last_name',
    'RegistrationDate': 'reg_date'
})

# Save to garbage4.csv
df.to_csv('garbage4.csv', index=False)

# Print 5 rows of the updated DataFrame
print(df.head())

# prompt: using the file garbage4.csv place each row in order as follow
# first_name, last_name, Phone, Country, Email, reg_date
# output new data to garbage5.csv

import pandas as pd

# Load the dataframe.
df = pd.read_csv('garbage4.csv')

# Reorder columns
new_order = ['first_name', 'last_name', 'Phone', 'Country', 'Email', 'reg_date']
df = df[new_order]

# Save to garbage5.csv
df.to_csv('garbage5.csv', index=False)

# Print 5 rows of the updated DataFrame
print(df.head())

# prompt: using garbage5.csv extract all fields containing 'Nan'
# extract invalid email
# to garbagePionex.csv
# output reflecting data to cleanPionex.csv

import pandas as pd

# Load the dataframe.
df = pd.read_csv('garbage5.csv')

# Extract rows with 'Nan' in any field
nan_rows = df[df.apply(lambda row: row.astype(str).str.contains('Nan').any(), axis=1)]

# Extract invalid emails (assuming invalid means not containing '@')
invalid_emails = df[~df['Email'].str.contains('@', na=False)]

# Save NaN rows to garbagePionex.csv
nan_rows.to_csv('garbagePionex.csv', index=False)

# Combine rows with 'Nan' and invalid emails, drop duplicates
combined_df = pd.concat([nan_rows, invalid_emails]).drop_duplicates()

# Remove rows with 'Nan' or invalid emails from original df
clean_df = df.drop(combined_df.index)


# Save cleaned data to cleanPionex.csv
clean_df.to_csv('cleanPionex.csv', index=False)

print("garbagePionex.csv created with rows containing 'Nan' and invalid emails.")
print("cleanPionex.csv created with cleaned data.")

# prompt: using garbagePionex check data for Nan values, check for invalid emails

import pandas as pd
import re

# Load the dataframe.
df = pd.read_csv('garbage5.csv')

# Function to check for valid email format
def is_valid_email(email):
    # Regular expression for basic email validation
    pattern = r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
    return bool(re.fullmatch(pattern, str(email)))


# Extract rows with 'Nan' in any field
nan_rows = df[df.apply(lambda row: row.astype(str).str.contains('Nan').any(), axis=1)]

# Extract invalid emails
invalid_emails = df[~df['Email'].apply(is_valid_email)]


# Save NaN rows and invalid emails to garbagePionex.csv
combined_df = pd.concat([nan_rows, invalid_emails]).drop_duplicates()
combined_df.to_csv('garbagePionex.csv', index=False)

# Remove rows with 'Nan' or invalid emails from original df
clean_df = df.drop(combined_df.index)

# Save cleaned data to cleanPionex.csv
clean_df.to_csv('cleanPionex.csv', index=False)

print("garbagePionex.csv created with rows containing 'Nan' and invalid emails.")
print("cleanPionex.csv created with cleaned data.")